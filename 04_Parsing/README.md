# Dependency Parsing report
I have used the UD_English-GUM dataset (https://github.com/UniversalDependencies/UD_English-GUM).
The output is present in the en_gum-ud-test_output.conllu file and the evaluation is present in the Parsing_evaluation.png image.

After analyzing the evaluation metrics of the model, including the UPOS, the model has attained 100% accuracy for most of the categories. Hence the dependency tree does not seem to have any significant errors. 
